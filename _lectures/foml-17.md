---
type: lecture
date: 2025-09-08
title: (foml-17) Discriminative Models - The Perceptron

# optional
# please use /static_files/notes directory to store notes
# thumbnail: /static_files/path/to/image.jpg

# optional
tldr: "An ad hoc learning strategy of adding/subtracting the samples to learn the optimal parameters of a linear discriminant."
  
# optional
# set it to true if you don't want this lecture to appear in the updates section
hide_from_announcments: false


# optional
links: 
    #- url: https://docs.google.com/presentation/d/1cRebvCNyQJlocFSw7ZdAgM7NPZMNd49_6jfU4V1Vgj4/edit?usp=sharing
    #  name: NN
    #- url: /static_files/presentations/dl-04.pdf
    #  name: Gradient Descent
    #- url: /static_files/presentations/dl-05.pdf
    #  name: Backprop-1
    - url: /static_files/presentations/foml-17.pdf
      name: slides
    #- url: /static_files/presentations/foml-17-annotated.pdf
    #  name: annotated-slides

---

**Suggested Reading**
- [Chapters 4.1.7 from Bishop book](https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)
- [Convergence proof for Perceptron](https://www.cse.iitb.ac.in/~shivaram/teaching/old/cs344+386-s2017/resources/classnote-1.pdf)
